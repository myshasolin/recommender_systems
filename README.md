<center>
  <h1>
    <a href="https://github.com/myshasolin/recommender_systems">
      здесь упражнения и самостоятельные проекты, выполненные в рамках курса "Рекомендательные системы", от простого (1) к сложному (8): 
    </a>
  </h1>
</center>

<table style="border: 2px double;">
  <tr>
    <th></th>
    <th>тема</th>
    <th>описание задания</th>
    <th>решение</th>
  </tr>
  <tr>
    <td>
      1
    </td>
    <td>
      <a href="https://github.com/myshasolin/recommender_systems/tree/main/1%20%D0%91%D0%B8%D0%B7%D0%BD%D0%B5%D1%81%20%D0%B8%20ML-%D0%BC%D0%B5%D1%82%D1%80%D0%B8%D0%BA%D0%B8">
        Бизнес и ML-метрики: Recall@k, Money Recall@k, MRR@k, nDCG@k
      </a>
    </td>
    <td>
      написать код метрик Recall@k, Money Recall@k, MRR@k, nDCG@k
    </td>
    <td>
      за основу нареписал крошечный датасет:<br>- recommended_list - список товаров, рекомендованных пользователю.<br>- bought_list - список товаров, купленных пользователем.<br>- prices_recommended - список цен на товары из recommended_list.<br>- prices_bought - список цен на товары из bought_list (в нём есть NaN).<br>Применяя каждую функцию, добавляю полученные значения как новый столбец к датасету + вывожу среднее
    </td>
  </tr>
  <tr>
    <td>
      2
    </td>
    <td>
      <a href="https://github.com/myshasolin/recommender_systems/tree/main/2%20%D0%91%D0%B5%D0%B9%D0%B7%D0%BB%D0%B0%D0%B9%D0%BD%D1%8B%20%D0%B8%20%D0%B4%D0%B5%D1%82%D0%B5%D1%80%D0%BC%D0%B8%D0%BD%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%20item-item">
        Бейзлайны и детерминированные алгоритмы item-item
      </a>
    </td>
    <td>
      Задание 1. Напишите код для случайных рекомендаций, в которых вероятность рекомендовать товар прямо пропорциональна логарифму продаж<br>Задание 2. Рассчитайте Precision@5 для каждого алгоритма. Какой алгоритм показывает лучшее качество?<br>Задание 3*. Улучшение бейзлайнов и ItemItem
    </td>
    <td>
      покрутил бейзлайны и детерминированные алгоритмы для разных значений и размеров выборок, а результат значений метрик precision@3, precision@5, recall@3, recall@5 для всех видов рекомендаций собрал в единую сводную таблицу + в конце отрисовал график по ней. Все свои шаги описал в Markdown-ячейках, в конце написал маленький вывод по выбору лучшего алгоритма и его характеристик
    </td>
  </tr>
  <tr>
    <td>
      3
    </td>
    <td>
      <a href="https://github.com/myshasolin/recommender_systems/tree/main/3%20%D0%9A%D0%BE%D0%BB%D0%BB%D0%B0%D0%B1%D0%BE%D1%80%D0%B0%D1%82%D0%B8%D0%B2%D0%BD%D0%B0%D1%8F%20%D1%84%D0%B8%D0%BB%D1%8C%D1%82%D1%80%D0%B0%D1%86%D0%B8%D1%8F">
        Коллаборативная фильтрация
      </a>
    </td>
    <td>
      Подбор оптимальных гиперпараметров для ALS<br>Задание:<br>Попробуйте улучшить базовый вариант ALS, изменяя следующие параметры: regularization, iterations, factors, вес (TF_IDF, BM25 взвешивание)<br>Посчитайте метрики (Precision@5, MAP@5) для разных наборов гиперпараметров и выберете лучший набор
    </td>
    <td>
      функции с метриками рукописные. Дальше в цикле перебираю аж 240 моделей и выбираю лучшую по метрикам. Она же, кстати, лучшей оказалась и по Precision@5 и по MAP@5
    </td>
  </tr>
  <tr>
    <td>
      4
    </td>
    <td>
      <a href="https://github.com/myshasolin/recommender_systems/tree/main/4%20%D0%A0%D0%B5%D0%BA%D0%BE%D0%BC%D0%B5%D0%BD%D0%B4%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B%20%D0%BD%D0%B0%20%D0%BE%D1%81%D0%BD%D0%BE%D0%B2%D0%B5%20%D0%BA%D0%BE%D0%BD%D1%82%D0%B5%D0%BD%D1%82%D0%B0">
        Рекомендательные системы на основе контента
      </a>
    </td>
    <td>
      Задание:<br>1. Перенесите метрики в модуль src.metrics.py<br>2. Перенесите функцию prefilter_items в модуль src.utils.py<br>3. Создайте модуль src.recommenders.py. Напишите код для класса ниже
    </td>
    <td>
      -директория src, а в ней 3 модуля:<br>metrics – здесь я собрал все метрики<br>utils – здесь функции get_result_table и prefilter_items<br>recommenders – здесь класс MainRecommender<br>-ipynb-скрипт, в котором я скачиваю данные, делю их на train и test и из рукописных модулей использую функции get_result_table, prefilter_items и класс MainRecommender<br>В MainRecommender я немного переписал логику, оставил его пока только на получение рекомендаций с помощью ALS, но зато добавил возможность получать как рекомендации для какого-то отдельного специально заданного пользователя, так и для всех сразу.
    </td>
  </tr>
  <tr>
    <td>
      5
    </td>
    <td>
      <a href="https://github.com/myshasolin/recommender_systems/tree/main/5%20%D0%9F%D0%BE%D0%B8%D1%81%D0%BA%20%D0%BF%D0%BE%D1%85%D0%BE%D0%B6%D0%B8%D1%85%20%D1%82%D0%BE%D0%B2%D0%B0%D1%80%D0%BE%D0%B2%20%D0%B8%20%D0%BF%D0%BE%D0%BB%D1%8C%D0%B7%D0%BE%D0%B2%D0%B0%D1%82%D0%B5%D0%BB%D0%B5%D0%B9.%20%D0%93%D0%B8%D0%B1%D1%80%D0%B8%D0%B4%D0%BD%D1%8B%D0%B5%20%D1%80%D0%B5%D0%BA%D0%BE%D0%BC%D0%B5%D0%BD%D0%B4%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B">
        Поиск похожих товаров и пользователей. Гибридные рекомендательные системы
      </a>
    </td>
    <td>
      Задание:<br>Разобраться с LightFM и перебрать гиперпараметры модели
    </td>
    <td>
      построил в цикле 162 модели, для каждой, перебирая гиперпараметры, посчитал Precision@5. Информацию по всем параметрам моделек собрал в единую сводную таблицу и в самом конце блокнота вывожу ТОП-5 лучших и худших моделей по precision, там же пара общих слов – это вывод.
    </td>
  </tr>
  <tr>
    <td>
      6
    </td>
    <td>
      <a href="https://github.com/myshasolin/recommender_systems/tree/main/6%20%D0%94%D0%B2%D1%83%D1%85%D1%83%D1%80%D0%BE%D0%B2%D0%BD%D0%B5%D0%B2%D1%8B%D0%B5%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8%20%D1%80%D0%B5%D0%BA%D0%BE%D0%BC%D0%B5%D0%BD%D0%B4%D0%B0%D1%86%D0%B8%D0%B9">
        Двухуровневые модели рекомендаций
      </a>
    </td>
    <td>
      Задание 1:<br>Попробуйте различные варианты генерации кандидатов. Какие из них дают наибольший recall@k ?<br>Задание 2:<br>Обучите модель 2-ого уровня, при этом:<br>-Добавьте минимум по 2 фичи для юзера, товара и пары юзер-товар<br>-Измерьте отдельно precision@5 модели 1-ого уровня и двухуровневой модели на data_val_lvl_2<br>-Вырос ли precision@5 при использовании двухуровневой модели?
    </td>
    <td>
      для задания немного переписал свой класс MainRecommender, добавив в него возможность возвращать предсказания и по MainRecommender (этого у меня изначально не было), так как это всё же немного побыстрее, чем ALS.<br>Для первого задания я собираю в единый список словари с рекомендациями в виде: [{id: [рекомендации]}], а потом считаю по значениям словарей среднее Recall в зависимости от количества рекомендаций для каждого пользователя (10, 50, 1000, 200, 500) и отрисовываю график того, как Recall меняется от количества рекомендаций<br>Для второго задания я графиков уже не рисую, но формирую датафреймы для трейна и теста, генерирую новые признаки (по user, по item и по паре user-item), обучаю модель LGBMClassifier и по полученным предсказаниям для 10-ти рекомендаций считаю среднее по AP@10 и Recall@10, особенно по Recall@10 видно, как круто после второго алгоритма вырастает качество предсказания.
    </td>
  </tr>
  <tr>
    <td>
      7
    </td>
    <td>
      <a href="https://github.com/myshasolin/recommender_systems/tree/main/7%20%D0%A0%D0%B5%D0%BA%D0%BE%D0%BC%D0%B5%D0%BD%D0%B4%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B%20%D0%B2%20%D0%B1%D0%B8%D0%B7%D0%BD%D0%B5%D1%81%D0%B5">
        Рекомендательные системы в бизнесе
      </a>
    </td>
    <td>
      Задание:<br>-Выбрать по 6 предсказаний пользователей<br>-Удаить фейковый эллемент 999999<br>-Для каждого пользователя доллжно остаться по 5 отсортированных предсказаний<br>-Посчиитать метрики map@5 и precision@5
    </td>
    <td>
      переписал класс MainRecommender, разделив на два MainDistributedRecommender и MatrixTransformation. В качестве первого алгоритма для рекомендательной системы сделал ALS из PySpark, а второй там LightFM и эта парочка успешно работает)) предсказания, правда, получаются немного хуже, чем у ItemItem и LGB, но это уже дело техники и гиперпараметров.
    </td>
  </tr>
  <tr>
    <td>
      8
    </td>
    <td>
      <a href="https://github.com/myshasolin/recommender_systems/tree/main/8%20%D0%A0%D0%B5%D0%BA%D0%BE%D0%BC%D0%B5%D0%BD%D0%B4%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B%20%D0%B2%20%D0%B1%D0%B8%D0%B7%D0%BD%D0%B5%D1%81%D0%B5">
        Рекомендательные системы в бизнесе
      </a>
    </td>
    <td>
      Задание:<br>сфоормировать по 5 рекомендаций пользователям на основе предложенных данных за 3-хнедельный период (с 96 по 98-ю включительно), проверить качество полученных рекомендаций при помощи Precision@k и MAP@5 на отложенной выборке.<br>Критерий успеха - преодолеть порог Precision@5 в 0.22
    </td>
    <td>
      за основу работы, я, по сути, взяли 6-е дз, так как оно очень успешное у меня тогда получилось, двухуровневый алгоритм, да ещё и с генерацией новых признаков. Для этой работы я заменил второй валидационный блок на файл retail_test.csv и полностью его отработал. На первом Item-Item-алгоритме подбирается 100 рекомендаций, на втором уже по 5 из этой сотни с заменой на популярные item для тех user, у кого до 5-ти количества не хватает.
    </td>
  </tr>
</table>
